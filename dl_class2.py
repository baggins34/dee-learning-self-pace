# -*- coding: utf-8 -*-
"""dl_class2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y4Gs0gvCUwOu3SutJaaU_Og1h3Smr_rb
"""

# Commented out IPython magic to ensure Python compatibility.
try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=True)
    COLAB = True
    print("Note: using Google CoLab")
#     %tensorflow_version 2.x
except:
    print("Note: not using Google CoLab")
    COLAB = False

!ls /content/drive/My\ Drive/Colab\ Notebooks

"""# **PART 1------------------------------------------------**"""

import os 
import pandas as pd

df = pd.read_csv("https://data.heatonresearch.com/data/t81-558/auto-mpg.csv")

print(df.head())

display(df.head())

pd.set_option('display.max_columns', 12)
pd.set_option('display.max_rows', 0)
display(df)

df = df.select_dtypes(include=["int", "float"])
headers = list(df.columns.values)
fields = list()

for field in headers:
  fields.append({'Name': field,
                 'Mean': df[field].mean(),
                 'Var': df[field].var(),
                 'Sdev': df[field].std()})
for field in fields:
  print(field)

df2 = pd.DataFrame(fields)
display(df2)

"""## **Missing Values**"""

df3 = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv", 
    na_values=['NA', '?'])
columns = list(df3.columns)

for column in columns:
  print(f"{column} has na? {pd.isnull(df3[column]).values.any()}")

med = df3["horsepower"].median()

df3["horsepower"] = df3["horsepower"].fillna(med)
print(f"horsepower has na? {pd.isnull(df3['horsepower']).values.any()}")

"""# **------------------ OUTLIERS ------------------------------------------------------------------**"""

# Remove all rows where the specified column is +/- standard deviation
import numpy as np

def remove_outliers(df, name, st):
  drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (st * df[name].std()))]
  df.drop(drop_rows, axis=0, inplace=True)

from sklearn import metrics 
from scipy.stats import zscore

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

med = df['horsepower'].median()
df['horsepower'] = df['horsepower'].fillna(med)

# Drop the name column
df.drop('name',1,inplace=True)

# Drop outliers in MPG column 
print(f"Length before dropping outliers: {len(df['mpg'])}")

remove_outliers(df, 'mpg', st = 2)

print(f"Length after dropping outliers: {len(df['mpg'])}")

display(df)

"""# **--------- Dropping Fields ---------**

Some fields are no value of neural network should be dropped. 

For ex: Removing Name column from MPG dataset.
"""

import pandas as pd 
import os 

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

print(f"Before dropping: {list(df.columns)}")

df.drop('name', axis=1, inplace=True)

print(f"After dropping: {list(df.columns)}")

"""# **----- Concatenating Rows and Columns --------**"""

import pandas as pd 
import os 

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

col_horsepower = df.horsepower
col_name = df.name

print("\n------------ Concatening Columns --------------")
result = pd.concat([col_name, col_horsepower], axis=1)
display(result)

print("\n------------ Concatening Rows ------------------")
second_result = pd.concat([df[:2], df[-2:]], axis=0)
display(second_result)

"""# **----------- Train & Test -----------**"""

import pandas as pd 
import numpy as np 
import os 

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

df = df.reindex(np.random.permutation(df.index))

mask = np.random.rand(len(df)) < 0.8
train = pd.DataFrame(df[mask])
test = pd.DataFrame(df[~mask])

print(f"Train df: {len(train)}")
print(f"Test df: {len(test)}")

"""**Converting data frame to a matrix**"""

df.values

df[['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',
       'acceleration', 'year', 'origin']].values

"""**Saving the dataframe**"""

import pandas as pd 
import numpy as np 
import os 

path = "."

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

filename_write = os.path.join(path, "auto-mpg-shuffle.csv")

df = df.reindex(np.random.permutation(df.index))

df.to_csv(filename_write, index=False)
print("Done")

"""**Saving Data Frame to a pickle**"""

import numpy as np 
import pandas as pd
import os 
import pickle 

path = "."

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

filename_write = os.path.join(path, "auto-mpg-shuffle.pkl")
df = df.reindex(np.random.permutation(df.index))

with open(filename_write,"wb") as fp:
    pickle.dump(df, fp)

"""# **PART 2 ----------------------------**"""

# Commented out IPython magic to ensure Python compatibility.
try:
#     %tensorflow_version 2.x
    COLAB = True
    print("Note: using Google CoLab")
except:
    print("Note: not using Google CoLab")
    COLAB = False

import os 
import pandas as pd 
from scipy.stats import zscore

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

display(df.head())

df.mpg = zscore(df.mpg)

display(df.head())

import pandas as pd

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv",
    na_values=['NA','?'])

pd.set_option('display.max_columns', 0)
pd.set_option('display.max_rows', 5)

display(df)

areas = list(df.area.unique())

print(f"Number of Areas: {len(areas)}")
print("Areas: ", areas)

dummies = pd.get_dummies(df['area'], prefix="area")
display(dummies.head())

df = pd.concat([df, dummies], axis=1)
df.drop("area", axis=1, inplace=True)
display(df.head())

import pandas as pd
import numpy as np

np.random.seed(43)

df = pd.DataFrame({"cont_9": np.random.rand(10)*100,
                   "cat_0": ['dog']*5 + ['cat']*5,
                   "cat_1": ['wolf']*9 + ['tiger']*1,
                   'y': [1, 0, 1, 1, 1, 1, 0, 0, 0, 0]})

display(df)

means_cat0 = df.groupby('cat_0')['y'].mean().to_dict()
means_cat0

df.y.mean()

def calc_smooth_mean(df1, df2, cat_name, target, weight):
    # Compute the global mean
    mean = df[target].mean()
    print("Mean: \n", mean)

    # Compute the number of values and the mean of each group
    agg = df.groupby(cat_name)[target].agg(['count', 'mean'])
    counts = agg['count']
    print("Counts: \n", counts)
    means = agg['mean']
    print("Means: \n", means)

    # Compute the "smoothed" means
    smooth = (counts * means + weight * mean) / (counts + weight)
    print("smooth: \n", smooth)
    print("-----------------------------------------------------------")
    # Replace each value by the according smoothed mean
    if df2 is None:
        return df1[cat_name].map(smooth)
    else:
        return df1[cat_name].map(smooth),df2[cat_name].map(smooth.to_dict())

WEIGHT = 5

df['cat_0_enc'] = calc_smooth_mean(df1=df, df2=None, 
    cat_name='cat_0', target='y', weight=WEIGHT)
df['cat_1_enc'] = calc_smooth_mean(df1=df, df2=None, 
    cat_name='cat_1', target='y', weight=WEIGHT)

pd.set_option('display.max_columns', 0)
pd.set_option('display.max_rows', 0)

display(df)

"""# **PART 3 ----------------------------------------------**"""

import os 
import numpy as np 
import pandas as pd 

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv", 
    na_values=['NA', '?'])

np.random.seed(42)
df = df.reindex(np.random.permutation(df.index))

display(df.head())

df.reset_index(inplace=True, drop=True)
display(df.head())

"""## **Sorting a dataset**"""

import os 
import pandas as pd

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv", 
    na_values=['NA', '?'])

df = df.sort_values(by="name", ascending=True)
print(f"The first car is: {df['name'].iloc[0]}")
display(df.head())

"""**Grouping a dataset**"""

import os 
import pandas as pd 

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv", 
    na_values=['NA', '?'])

g = df.groupby("cylinders")['mpg'].mean()
display(g)

d = g.to_dict()
d

cylinders = list(df.groupby("cylinders")["mpg"].count())
print(cylinders)
sum(cylinders)

df.groupby("cylinders")["mpg"].count().to_dict()

"""# **PART 4 -------------------------------**

**MAP**
"""

import os 
import pandas as pd 
import numpy as np

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv", 
    na_values=['NA', '?'])

df["origin_name"] = df.origin.map({1: "North America", 2: "Europe", 3: "Asia"})

df = df.reindex(np.random.permutation(df.index))
display(df.head())

"""**APPLY**"""

efficieny = df.apply(lambda x: x['displacement']/x['horsepower'], axis=1)
display(efficieny.head())

df['efficieny'] = efficieny
display(df.head())

"""# **US Government Public Data**"""

import pandas as pd 

df = pd.read_csv('https://www.irs.gov/pub/irs-soi/16zpallagi.csv')

display(df.head())
print(df.shape)

"""Here in the data, we have so many columns. However, we'll only need:

- STATE
- zipcode
- agi_stub (Six different brackets of annual income 1 through 6)
- N1 (Number of tax returns for each of the agi_stub)

Since there is 6 agi_stub, we'll have 6 rows for the same zipcode and we can skip zipcodes with 0 or 99999.

Consider the values for N1. Based on N1:

- 1 = 1 to 25,000
- 2 = 25,000 to 50,000
- 3 = 50,000 to 75,000
- 4 = 75,000 to 100,000
- 5 = 100,000 to 200,000
- 6 = 200,000 or more 

The median of each of these ranges are:
- 1 = 12,500
- 2 = 37,500
- 3 = 62,500
- 4 = 87,500
- 5 = 112,500
- 6 = 212,500
"""

df = df.loc[(df["zipcode"] != 0) & (df["zipcode"] != 0), ["STATE", "zipcode", "agi_stub", "N1"]]
display(df.head())

"""We can replace all of the agi_stub values with the correct median values by using map() functiom"""

medians = {1:12500,2:37500,3:62500,4:87500,5:112500,6:212500}

df["agi_stub"] = df.agi_stub.map(medians)
display(df.head())

groups = df.groupby(by="zipcode")

df = pd.DataFrame(groups.apply(lambda x: sum(x["N1"]*x["agi_stub"])/sum(x['N1']))).reset_index()
display(df)

df.columns = ["zipcode", "agi_estimated"]
display(df.head())

"""Check if it is correct"""

df[df["zipcode"]==63017]

"""## **PART 5 -----------------------------**"""

import os 
import pandas as pd 

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv", 
    na_values=['NA', '?'])

display(df.head())

df.insert(loc=1, column= "weight-kg", value=(df["weight"]*0.45359237).astype(int))
display(df.head())

